# NLTK-Corpora-Analysis üìöüîç

## Objective

Use the NLTK library to open a corpus and perform different types of analysis.

## Instructions

Complete the following tasks. Make sure to write clean, commented, and well-structured code for each task. Non-commented code will be penalized. Submit your jupyter notebook file as YOURNAME_SURNAME_assignment3.ipynb

## Overview

1. **Subtask 1: Install and Import NLTK**
2. **Subtask 2: Sentence and Word Tokenization**
3. **Subtask 3: Bigrams, Trigrams, and POS Tagging**
4. **Subtask 4: Stemming, Lemmatization, and Frequency Distribution**


## Subtask 1: Install and Import NLTK
**Instructions:**
1. Install the NLTK library if you haven't already.
2. Import the necessary modules from NLTK.
3. Download the required NLTK data files to complete the next subtasks.


## Subtask 2: Sentence and Word Tokenization
**Instructions:**
1. Open the Gutenberg corpus.
2. Choose a specific file (e.g., 'austen-emma.txt') and tokenize it into sentences.
3. Print the total number of sentences and the first sentence.
4. Tokenize the text into words and print the tokens.


## Subtask 3: Bigrams, Trigrams, and POS Tagging
**Instructions:**
1. Generate bigrams and trigrams from the word tokens and print the first 10 of each.
2. Perform POS tagging on the word tokens and print the first 10 tokens with their POS tags.


## Subtask 4: Stemming, Lemmatization, and Frequency Distribution
**Instructions:**
1. Stem each word token and print the original token, its POS tag, and its stem.
2. Lemmatize each word token and print the original token and its lemma.
3. Create a frequency distribution of the word tokens and plot the top 20 words.
